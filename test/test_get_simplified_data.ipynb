{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from data.scripts.simplified_finance_stats.fin_stats import fin_stats\n",
    "from data.scripts.simplified_finance_stats.fin_ratios import get_ratios\n",
    "from data.scripts.simplified_finance_stats.fin_stats_2 import fin_stats_2\n",
    "from report_13f.brk.company_13f import company_13f\n",
    "from data.scripts.build_training_data.train_data import train_data\n",
    "\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set path for data\n",
    "base_path = '../data/'\n",
    "data_path = 'combined_simplified/combined_all_us.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup all data\n",
    "finances = fin_stats(base_path + data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl_b = finances.get_sheet(\"AAPL\",\"balance_sheet\")\n",
    "aapl_i = finances.get_sheet(\"AAPL\",\"income_sheet\")\n",
    "aapl_c = finances.get_sheet(\"AAPL\",\"cashflow_sheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = fin_stats_2(base_path + 'combined_simplified/others_all_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl_o = o.get_sheet('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl_fin_stats = pd.concat([aapl_b,aapl_i,aapl_c,aapl_o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl_ratio = get_ratios(aapl_b,aapl_i,aapl_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aapl_df = pd.concat([aapl_fin_stats,aapl_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl_T = aapl_df.transpose()\n",
    "y = aapl_T.as_matrix()\n",
    "x = np.array(aapl_T.index.tolist())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.polyfit(x,y,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,feature in enumerate(aapl_T.columns.tolist()):\n",
    "    \n",
    "    real = aapl_T[feature].values\n",
    "    pred = p[0,i]*x**3 + p[1,i]*x**2 + p[2,i]*x + p[3,i]\n",
    "\n",
    "    plt.plot(x,real,'-',label='Real')\n",
    "    plt.plot(x,pred,'--',label='Predicted')\n",
    "    plt.plot(x,pred,'.',label='Pred Points')\n",
    "    plt.title(feature)\n",
    "    plt.xlabel('Years')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./test_plots/\" + feature + \".jpg\")\n",
    "    plt.clf()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get company timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data.scripts.company_list.company_timeline import company_timeline as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = '../data/cash_flow/cash_flow_all_us_list.csv'\n",
    "c = ct(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.get_timeline('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code = \"D:\\\\FA\\\\report_13f\\\\brk\\\\company_13f.py\"\n",
    "%run $code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isinstance('abc',str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test train_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brk_path = \"D:\\\\FA\\\\report_13f\\\\brk\\\\13f_brk.csv\"\n",
    "c = company_13f(brk_path)\n",
    "y_2016 = c.get_positive(2016)\n",
    "\n",
    "t_data = train_data(y_2016)\n",
    "\n",
    "inp_data_10 = t_data.get_hist_data(10)\n",
    "\n",
    "names,data = t_data.transform_c_to_1d(inp_data_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of dataframe before filling missing names:\n",
      "No. of missing fields 152\n",
      "\n",
      "\n",
      "Ticker not in the current database. Removing LIBERTY MEDIA CORP\n",
      "Ticker not in the current database. Removing STARZ\n",
      "Ticker not in the current database. Removing MGOC INC\n",
      "\n",
      "\n",
      "All values Filled\n",
      "\n",
      "\n",
      "Getting Data for:\n",
      "AXP\n",
      "KO\n",
      "COST\n",
      "DVA\n",
      "GE\n",
      "GM\n",
      "GS\n",
      "GHC\n",
      "JNJ\n",
      "KMI\n",
      "KHC\n",
      "LEE\n",
      "MTB\n",
      "MEG\n",
      "'[2016] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 1993 to 2015\n",
      "\n",
      "\n",
      "MDLZ\n",
      "MCO\n",
      "DNOW\n",
      "'[2006 2007 2008 2009 2010] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 2011 to 2016\n",
      "\n",
      "\n",
      "QSR\n",
      "SNY\n",
      "SU\n",
      "TMK\n",
      "FOXA\n",
      "USB\n",
      "USG\n",
      "UPS\n",
      "VRSN\n",
      "VZ\n",
      "VRSK\n",
      "'[2006] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 2007 to 2016\n",
      "\n",
      "\n",
      "WFC\n",
      "AXP\n",
      "BK\n",
      "KO\n",
      "COST\n",
      "DVA\n",
      "GE\n",
      "GM\n",
      "GS\n",
      "GHC\n",
      "IBM\n",
      "JNJ\n",
      "KMI\n",
      "KHC\n",
      "LEE\n",
      "MTB\n",
      "MA\n",
      "MEG\n",
      "'[2016] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 1993 to 2015\n",
      "\n",
      "\n",
      "MDLZ\n",
      "MCO\n",
      "DNOW\n",
      "'[2006 2007 2008 2009 2010] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 2011 to 2016\n",
      "\n",
      "\n",
      "PG\n",
      "QSR\n",
      "SNY\n",
      "TMK\n",
      "FOXA\n",
      "USB\n",
      "USG\n",
      "UPS\n",
      "VZ\n",
      "VRSK\n",
      "'[2006] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 2007 to 2016\n",
      "\n",
      "\n",
      "V\n",
      "WBC\n",
      "WFC\n",
      "AXP\n",
      "CHTR\n",
      "KO\n",
      "COST\n",
      "DVA\n",
      "GE\n",
      "GM\n",
      "GS\n",
      "GHC\n",
      "IBM\n",
      "JNJ\n",
      "KHC\n",
      "MTB\n",
      "MA\n",
      "MDLZ\n",
      "MCO\n",
      "PSX\n",
      "'[2006 2007 2008 2009] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 2010 to 2016\n",
      "\n",
      "\n",
      "PG\n",
      "QSR\n",
      "SNY\n",
      "TMK\n",
      "FOXA\n",
      "USB\n",
      "USG\n",
      "UPS\n",
      "VRSN\n",
      "VRSK\n",
      "'[2006] not in index'\n",
      "Data range requested 2006 to 2016\n",
      "Data only available from 2007 to 2016\n",
      "\n",
      "\n",
      "V\n",
      "WBC\n",
      "WFC"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Anaconda2\\lib\\site-packages\\numpy\\lib\\polynomial.py:594: RankWarning: Polyfit may be poorly conditioned\n",
      "  warnings.warn(msg, RankWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['USG', 'AXP', 'USB', 'WFC', 'DVA', 'KMI', 'BK', 'COST', 'WBC', 'GHC', 'TMK', 'VZ', 'IBM', 'MDLZ', 'PG', 'KHC', 'GS', 'GE', 'V', 'MTB', 'GM', 'UPS', 'MCO', 'VRSN', 'MA', 'LEE', 'FOXA', 'KO', 'SU', 'QSR', 'CHTR', 'JNJ', 'SNY']\n",
      "(33L, 460L)\n"
     ]
    }
   ],
   "source": [
    "code_tdata = \"D:\\\\FA\\\\data\\\\scripts\\\\build_training_data\\\\train_data.py\"\n",
    "%run $code_tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = \"D:\\\\FA\\\\data\\\\combined_simplified\\\\combined_all_us.csv\"\n",
    "df = pd.read_csv(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance(\"abc\",\"cba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp_str = \"KRAFT FOODS GROUP\"\n",
    "\n",
    "def get_tic(df,inp_str):\n",
    "    # Returns the tic symbol matching the name of the company\n",
    "    # using levenshtein distance in sequence.\n",
    "    # Starting with the first element and matching sequentially\n",
    "    \n",
    "    df = df.drop_duplicates().reset_index()\n",
    "    df['conm'] = df['conm'].str.split()\n",
    "    df_s = df['conm']\n",
    "    inp_str_s = inp_str.split()\n",
    "    \n",
    "    len_inp = len(inp_str_s)\n",
    "    \n",
    "    for i in range(len_inp):\n",
    "        test_str = inp_str_s[i]\n",
    "        # Get nth element of the name\n",
    "        # eg: ['KRAFT','HEINZ','GROUP']\n",
    "        df_i = df_s.apply(lambda x: get_n_element(x,i))\n",
    "        # Remove empty lists\n",
    "        df_i = df_i[[x != [] for x in df_i.values]]\n",
    "        # similarity check using Levenshtein distance\n",
    "        df_dist = df_i.apply(lambda x: distance(x,test_str))\n",
    "        min_dist = df_dist.min()\n",
    "        idxmin_dist = df_dist.idxmin()\n",
    "        # Compare the min distance\n",
    "        idx_dist = df_dist[df_dist == min_dist].index\n",
    "        \n",
    "        if len(idx_dist) == 1 and min_dist < 3:\n",
    "            tic_idx = idx_dist.values[0]\n",
    "            tic = df['tic'].iloc[tic_idx]\n",
    "            return tic\n",
    "        \n",
    "        elif len(idx_dist) == 1 and min_dist >= 3:\n",
    "            print(\"Company Not found\")\n",
    "            tic = \"NOT FOUND\"\n",
    "            return tic\n",
    "        \n",
    "        if (i+1 == len_inp):\n",
    "            print(\"Multiple names found without exact match\")\n",
    "            tic = \"NOT FOUND\"\n",
    "            return tic\n",
    "        \n",
    "    \n",
    "def get_n_element(l,n):\n",
    "    try:\n",
    "        return l[n]\n",
    "    except:\n",
    "        return []\n",
    "        \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = 'PHILLIPS'\n",
    "dff = df[['tic','conm']].copy()\n",
    "bb = get_tic(dff,A)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_s = dff['conm'].str.split(\" \")\n",
    "inp_str = \"AAR CORP\".split(\" \")\n",
    "inp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x==inp_str for x in df_s.values].index(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels are found in line 24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Project Name\n",
    "file_name = \"<project_name>\"\n",
    "des_path = '../../../../'\n",
    "\n",
    "# read des file\n",
    "#f = open(des_path + file_name +'.des','rb')\n",
    "f = open('test.des','rb')\n",
    "lines = f.readlines()\n",
    "line_end = len(lines)\n",
    "\n",
    "# Find the line with variable names\n",
    "for i in range(len(lines)):\n",
    "    line_tmp = lines[i].split()\n",
    "\n",
    "    try:\n",
    "        if line_tmp[0]=='<ID>':\n",
    "            print(\"Labels are found in line %i\"%i)\n",
    "            print(\"\\n\")\n",
    "            label_line = line_tmp\n",
    "            label_line_id = i\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "tmp = lines[label_line_id::] \n",
    "designs = [x.split() for x in tmp]\n",
    "\n",
    "with open(\"output.csv\", \"wb\") as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerows(designs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
